{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagename</th>\n",
       "      <th>postid</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset.1</th>\n",
       "      <th>postdate</th>\n",
       "      <th>Contents</th>\n",
       "      <th>url</th>\n",
       "      <th>Q1_pertain_to_covid</th>\n",
       "      <th>Q2_cetegory</th>\n",
       "      <th>Q2A_Type of Human</th>\n",
       "      <th>...</th>\n",
       "      <th>Q8_threat_covid</th>\n",
       "      <th>Q9_susceptibility_covid</th>\n",
       "      <th>Q9A_Asian responsible for the covid</th>\n",
       "      <th>Q10_solution_present</th>\n",
       "      <th>Q11_recommended_solution</th>\n",
       "      <th>misinformation</th>\n",
       "      <th>Q12 Presence of conspiracy theory</th>\n",
       "      <th>Q12-Others</th>\n",
       "      <th>Q13.  Image of plague doctor costume</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-A5FIIIEKJ</td>\n",
       "      <td>5592</td>\n",
       "      <td>middle</td>\n",
       "      <td>2</td>\n",
       "      <td>3/21/20</td>\n",
       "      <td>#covid #covid2020 #covidvirus #virus #coronava...</td>\n",
       "      <td>https://www.instagram.com/p/B-A5FIIIEKJ/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stay home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-A74YQn_4a</td>\n",
       "      <td>5593</td>\n",
       "      <td>middle</td>\n",
       "      <td>2</td>\n",
       "      <td>3/21/20</td>\n",
       "      <td>Well this is the final mural of my trip in Aus...</td>\n",
       "      <td>https://www.instagram.com/p/B-A74YQn_4a/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-AajnDp6GQ</td>\n",
       "      <td>5575</td>\n",
       "      <td>middle</td>\n",
       "      <td>2</td>\n",
       "      <td>3/21/20</td>\n",
       "      <td>Chegamos !!! V√£o seguindo o movimento... Tem m...</td>\n",
       "      <td>https://www.instagram.com/p/B-AajnDp6GQ/</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-AarR4pUQA</td>\n",
       "      <td>5576</td>\n",
       "      <td>middle</td>\n",
       "      <td>2</td>\n",
       "      <td>3/21/20</td>\n",
       "      <td>üòªüòªüòªüòªüòª</td>\n",
       "      <td>https://www.instagram.com/p/B-AarR4pUQA/</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-AE1y3HD-Z</td>\n",
       "      <td>5550</td>\n",
       "      <td>middle</td>\n",
       "      <td>2</td>\n",
       "      <td>3/21/20</td>\n",
       "      <td>EN MI DOMICILIO üè°\\r\\r\\r\\r\\n#quedateencasa\\r\\r\\...</td>\n",
       "      <td>https://www.instagram.com/p/B-AE1y3HD-Z/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>mask; Stay home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9643</th>\n",
       "      <td>CEZyheBgtMd</td>\n",
       "      <td>8402</td>\n",
       "      <td>second</td>\n",
       "      <td>3</td>\n",
       "      <td>8/27/20</td>\n",
       "      <td>#water #foryou #followforfollowback #photograp...</td>\n",
       "      <td>https://www.instagram.com/p/CEZyheBgtMd/</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9644</th>\n",
       "      <td>CEZYoyRluKG</td>\n",
       "      <td>8352</td>\n",
       "      <td>second</td>\n",
       "      <td>3</td>\n",
       "      <td>8/27/20</td>\n",
       "      <td>#like4likes #20likes #tagforlikes #instalikes ...</td>\n",
       "      <td>https://www.instagram.com/p/CEZYoyRluKG/</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9645</th>\n",
       "      <td>CEZz-solaUF</td>\n",
       "      <td>8403</td>\n",
       "      <td>second</td>\n",
       "      <td>3</td>\n",
       "      <td>8/27/20</td>\n",
       "      <td>üôàü•∞üòçüëâüèΩ @love_serie_karma #daancorona #daancoron...</td>\n",
       "      <td>https://www.instagram.com/p/CEZz-solaUF/</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9646</th>\n",
       "      <td>CEZZ4P4j3rh</td>\n",
       "      <td>8354</td>\n",
       "      <td>second</td>\n",
       "      <td>3</td>\n",
       "      <td>8/27/20</td>\n",
       "      <td>üí•üö® ùóôùóîùóüùóü ùóúùó¶ ùóñùó¢ùó†ùóúùó°ùóö üö®üí•‚Å£\\r\\r\\r\\r\\r\\n‚Å£\\r\\r\\r\\r\\r\\n...</td>\n",
       "      <td>https://www.instagram.com/p/CEZZ4P4j3rh/</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9647</th>\n",
       "      <td>CEZZyqshFLq</td>\n",
       "      <td>8353</td>\n",
       "      <td>second</td>\n",
       "      <td>3</td>\n",
       "      <td>8/27/20</td>\n",
       "      <td>Follow me @kestine_kylie \\r\\r\\r\\r\\n.\\r\\r\\r\\r\\n...</td>\n",
       "      <td>https://www.instagram.com/p/CEZZyqshFLq/</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9589 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        imagename  postid dataset  dataset.1 postdate  \\\n",
       "0     B-A5FIIIEKJ    5592  middle          2  3/21/20   \n",
       "1     B-A74YQn_4a    5593  middle          2  3/21/20   \n",
       "2     B-AajnDp6GQ    5575  middle          2  3/21/20   \n",
       "3     B-AarR4pUQA    5576  middle          2  3/21/20   \n",
       "4     B-AE1y3HD-Z    5550  middle          2  3/21/20   \n",
       "...           ...     ...     ...        ...      ...   \n",
       "9643  CEZyheBgtMd    8402  second          3  8/27/20   \n",
       "9644  CEZYoyRluKG    8352  second          3  8/27/20   \n",
       "9645  CEZz-solaUF    8403  second          3  8/27/20   \n",
       "9646  CEZZ4P4j3rh    8354  second          3  8/27/20   \n",
       "9647  CEZZyqshFLq    8353  second          3  8/27/20   \n",
       "\n",
       "                                               Contents  \\\n",
       "0     #covid #covid2020 #covidvirus #virus #coronava...   \n",
       "1     Well this is the final mural of my trip in Aus...   \n",
       "2     Chegamos !!! V√£o seguindo o movimento... Tem m...   \n",
       "3                                                 üòªüòªüòªüòªüòª   \n",
       "4     EN MI DOMICILIO üè°\\r\\r\\r\\r\\n#quedateencasa\\r\\r\\...   \n",
       "...                                                 ...   \n",
       "9643  #water #foryou #followforfollowback #photograp...   \n",
       "9644  #like4likes #20likes #tagforlikes #instalikes ...   \n",
       "9645  üôàü•∞üòçüëâüèΩ @love_serie_karma #daancorona #daancoron...   \n",
       "9646  üí•üö® ùóôùóîùóüùóü ùóúùó¶ ùóñùó¢ùó†ùóúùó°ùóö üö®üí•‚Å£\\r\\r\\r\\r\\r\\n‚Å£\\r\\r\\r\\r\\r\\n...   \n",
       "9647  Follow me @kestine_kylie \\r\\r\\r\\r\\n.\\r\\r\\r\\r\\n...   \n",
       "\n",
       "                                           url  Q1_pertain_to_covid  \\\n",
       "0     https://www.instagram.com/p/B-A5FIIIEKJ/                    1   \n",
       "1     https://www.instagram.com/p/B-A74YQn_4a/                    1   \n",
       "2     https://www.instagram.com/p/B-AajnDp6GQ/                    2   \n",
       "3     https://www.instagram.com/p/B-AarR4pUQA/                    2   \n",
       "4     https://www.instagram.com/p/B-AE1y3HD-Z/                    1   \n",
       "...                                        ...                  ...   \n",
       "9643  https://www.instagram.com/p/CEZyheBgtMd/                    2   \n",
       "9644  https://www.instagram.com/p/CEZYoyRluKG/                    2   \n",
       "9645  https://www.instagram.com/p/CEZz-solaUF/                    2   \n",
       "9646  https://www.instagram.com/p/CEZZ4P4j3rh/                    2   \n",
       "9647  https://www.instagram.com/p/CEZZyqshFLq/                    2   \n",
       "\n",
       "      Q2_cetegory  Q2A_Type of Human  ...  Q8_threat_covid  \\\n",
       "0               1                  1  ...                1   \n",
       "1               1                  1  ...                1   \n",
       "2              99                 99  ...               99   \n",
       "3              99                 99  ...               99   \n",
       "4               1                  1  ...                1   \n",
       "...           ...                ...  ...              ...   \n",
       "9643           99                 99  ...               99   \n",
       "9644           99                 99  ...               99   \n",
       "9645           99                 99  ...               99   \n",
       "9646           99                 99  ...               99   \n",
       "9647           99                 99  ...               99   \n",
       "\n",
       "      Q9_susceptibility_covid  Q9A_Asian responsible for the covid  \\\n",
       "0                           1                                    2   \n",
       "1                           1                                    2   \n",
       "2                          99                                   99   \n",
       "3                          99                                   99   \n",
       "4                           1                                    2   \n",
       "...                       ...                                  ...   \n",
       "9643                       99                                   99   \n",
       "9644                       99                                   99   \n",
       "9645                       99                                   99   \n",
       "9646                       99                                   99   \n",
       "9647                       99                                   99   \n",
       "\n",
       "      Q10_solution_present  Q11_recommended_solution  misinformation  \\\n",
       "0                        1                         1               0   \n",
       "1                        2                        99               0   \n",
       "2                       99                        99               0   \n",
       "3                       99                        99               0   \n",
       "4                        1                         1               0   \n",
       "...                    ...                       ...             ...   \n",
       "9643                    99                        99               0   \n",
       "9644                    99                        99               0   \n",
       "9645                    99                        99               0   \n",
       "9646                    99                        99               0   \n",
       "9647                    99                        99               0   \n",
       "\n",
       "      Q12 Presence of conspiracy theory  Q12-Others  \\\n",
       "0                                     2          99   \n",
       "1                                     2          99   \n",
       "2                                    99          99   \n",
       "3                                    99          99   \n",
       "4                                     2          99   \n",
       "...                                 ...         ...   \n",
       "9643                                 99          99   \n",
       "9644                                 99          99   \n",
       "9645                                 99          99   \n",
       "9646                                 99          99   \n",
       "9647                                 99          99   \n",
       "\n",
       "      Q13.  Image of plague doctor costume             Note  \n",
       "0                                      2.0        Stay home  \n",
       "1                                      2.0              NaN  \n",
       "2                                     99.0              NaN  \n",
       "3                                     99.0              NaN  \n",
       "4                                      2.0  mask; Stay home  \n",
       "...                                    ...              ...  \n",
       "9643                                  99.0              NaN  \n",
       "9644                                  99.0              NaN  \n",
       "9645                                  99.0              NaN  \n",
       "9646                                  99.0              NaN  \n",
       "9647                                  99.0              NaN  \n",
       "\n",
       "[9589 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ins_df = pd.read_csv('data/instagram_data.csv')\n",
    "ins_df = ins_df[ins_df['Contents'].notna()] # We might want to do something different here - SN\n",
    "ins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>#aliens #zombie #gore #slash #ghost #sith #hor...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>@TouchPH  The solution is to punish the crimin...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>I think they may be #offended</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>SOMEONE LET SNAKES IN MY HOUSE, I BET IT @Ya_B...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>#NewYork: Several #Baloch &amp;amp; Indian activis...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>@Olajide_Shutti lmaoo. It will be a joyful day.</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>@Miami4Trump Yeah, but bad part is the #terror...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Peter is aesthetically pleasing to look at</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>I had a panic attack when I couldn't find @kat...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Had a dream last night that Chris Brown create...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3613 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet category\n",
       "903  #aliens #zombie #gore #slash #ghost #sith #hor...     fear\n",
       "392  @TouchPH  The solution is to punish the crimin...  sadness\n",
       "415                      I think they may be #offended    anger\n",
       "121  SOMEONE LET SNAKES IN MY HOUSE, I BET IT @Ya_B...    anger\n",
       "349  #NewYork: Several #Baloch &amp; Indian activis...     fear\n",
       "..                                                 ...      ...\n",
       "154    @Olajide_Shutti lmaoo. It will be a joyful day.      joy\n",
       "283  @Miami4Trump Yeah, but bad part is the #terror...     fear\n",
       "263         Peter is aesthetically pleasing to look at      joy\n",
       "62   I had a panic attack when I couldn't find @kat...     fear\n",
       "636  Had a dream last night that Chris Brown create...  sadness\n",
       "\n",
       "[3613 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "anger_df = pd.read_csv('data/twitter/anger.tsv', sep='\\t').drop(columns=['index', 'intensity'])\n",
    "fear_df = pd.read_csv('data/twitter/fear.tsv', sep='\\t').drop(columns=['index', 'intensity'])\n",
    "joy_df = pd.read_csv('data/twitter/joy.tsv', sep='\\t').drop(columns=['index', 'intensity'])\n",
    "sadness_df = pd.read_csv('data/twitter/sadness.tsv', sep='\\t').drop(columns=['index', 'intensity'])\n",
    "\n",
    "emotion_df = pd.concat([anger_df, fear_df, joy_df, sadness_df])\n",
    "emotion_df = shuffle(emotion_df)\n",
    "\n",
    "emotion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (4.12.5)\n",
      "Requirement already satisfied: datasets in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (1.16.1)\n",
      "Requirement already satisfied: emoji in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (1.6.1)\n",
      "Requirement already satisfied: deep-translator in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (1.5.5)\n",
      "Requirement already satisfied: requests in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from transformers) (0.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages/numpy-1.19.5-py3.8-linux-x86_64.egg (from transformers) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: xxhash in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from datasets) (6.0.0)\n",
      "Requirement already satisfied: pandas in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: multiprocess in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: dill in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from datasets) (2021.11.0)\n",
      "Requirement already satisfied: aiohttp in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from deep-translator) (4.10.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.0.1 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from deep-translator) (8.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.2.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /usr3/graduate/nelsonso/.local/lib/python3.8/site-packages (from aiohttp->datasets) (3.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: joblib in /share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.8.10/install/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers datasets emoji deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from deep_translator import GoogleTranslator\n",
    "import emoji\n",
    "# MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\" \n",
    "# MODEL = \"digitalepidemiologylab/covid-twitter-bert-v2\"\n",
    "MODEL = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "# Note: How we preprocess may depend on model we use to transfer. \n",
    "# This comes from https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = '' if t.startswith('http') else t\n",
    "        t = t.replace('\\r', '')\n",
    "        t = t.replace(\"\\n\", \" \") # Remove newlines\n",
    "        \n",
    "        # Remove hashtags but keep words\n",
    "        t = ' '.join(t.split(\"#\")) if '#' in t else t\n",
    "#         t = '' if len(t.split()) == 0 else t\n",
    "#         t = '' if len(t.split()) == 1 and t.split()[0] == '#' else t # remove empty \"#\"\n",
    "#         if len(t.split(\"#\")) > 1:\n",
    "#             t = ' #'.join(t.split(\"#\"))[1:] # separate hashtags\n",
    "            \n",
    "        # change emojis to be explanation of emoji\n",
    "        if emoji.get_emoji_regexp().search(t) != None:\n",
    "            t = ' '.join(emoji.demojize(i) for i in emoji.get_emoji_regexp().split(t))\n",
    "            t = t.replace(\"_\",\" \")\n",
    "            t = t.replace(\"-\",\" \")\n",
    "            t = t.replace(\":\",\" \")\n",
    "    #         t = emoji.get_emoji_regexp().sub(\"\", t)\n",
    "    \n",
    "        t = \" \".join(t.split()) # Remove excess whitespace\n",
    "        new_text.append(t)\n",
    "    \n",
    "    cleaned_text = \" \".join(new_text)\n",
    "     try:\n",
    "         cleaned_text = translator.translate(cleaned_text) # Translate non english to english\n",
    "     except Exception as e:\n",
    "         print(e)\n",
    "    \n",
    "    if len(cleaned_text.split()) == 0: return text # return original text if our cleaning made empty string\n",
    "    return cleaned_text\n",
    "\n",
    "# Load data into numpy arrays\n",
    "X = np.array(emotion_df['tweet'])\n",
    "Y = np.array(emotion_df['category'])\n",
    "Y_ints = np.array(pd.factorize(emotion_df['category'])[0])\n",
    "X_ins = np.array(ins_df['Contents'])\n",
    "east_asian = np.array(ins_df['Q5A.  If yes to Q5, what type of Asian'] == 1, dtype=int)\n",
    "\n",
    "# Preprocess text\n",
    "for i in range(len(X)):     X[i] = preprocess(X[i])\n",
    "for i in range(len(X_ins)): X_ins[i] = preprocess(X_ins[i])\n",
    "# for i in range(30): \n",
    "#     print(X_ins[i])\n",
    "#     print('---')\n",
    "#     X_ins[i] = preprocess(X_ins[i])\n",
    "# #     print(X_ins[i])\n",
    "#     print()\n",
    "#     print()\n",
    "\n",
    "# Split into train/val/test sets\n",
    "TRAIN_PCT, VAL_PCT, TEST_PCT  = 0.6, 0.2, 0.2\n",
    "train_idx = int(TRAIN_PCT * len(X))\n",
    "val_idx = train_idx + int(VAL_PCT * len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid covid2020 covidvirus virus coronavairus coronavirus coronav√≠rus coronavir√ºs blackandwhite blackandwhiteportrait blackandwhitephoto blackandwhite_photos lockdown lockdown2020 lockdownlife lockdownitaly italylockdown lockdowndiaries lockdownactivities stayathome staysafe stayhome iorestoacasa myhome covid19 covƒ±d19 coviÃád_19 coviditalia black heart black heart black heart black heart\n",
      "Well this is the final mural of my trip in Australia, a very weird trip, to be honest I couldn‚Äôt connect with my painting, at the beginning it was a popular psicosis which looked unreal, then the airline call me with news that my flights was rebooked for 4 month later, I still had a lot to do, people to meet and paint to make, it was super sad when I had to buy another thicket a week before of planed and run out of the country, the same day they closed the border, I like to think that everything happens for reason, everything is meant to be ... if this is my way to start the painting tour this year I don‚Äôt really know what to expect. When I painted the mural I meant to make something for the woman, for warriors who don‚Äôt want anybody to tell them what to do or say, now it feels empty cos the world is thinking on a different thing. Thank you to my new friend  who really helped and connect with me, what a beautiful city melbourne, what a beautiful country Australia, I hope to be back some day for more projects. Be safe and do what you‚Äôre told, this is not a joke. graff graffiti mural muralart muralgraffiti streetart artecallejero portrait retraro painting pintura realismo realism hiperrealismo hyperrealism portrait retrato onlyspraypaint onlyspray noproyector sinproyector cobreart melbourne australia graffitiaustralia corona coronavirus\n",
      "Chegamos !!! V√£o seguindo o movimento... Tem muita coisa que estamos preparando pra voc√™s!!!\n",
      "smiling cat with heart eyes smiling cat with heart eyes smiling cat with heart eyes smiling cat with heart eyes smiling cat with heart eyes\n",
      "EN MI DOMICILIO house with garden quedateencasa mobile phone with arrow 0414-464.18.89 . USA TAPA BOCAS face with medical mask . Tapa bocas seguros y c√≥modos Un obsequio de   bikini Graciasss . A√∫n en nuestro hogares deber√≠amos usa tapa bocas, al usar algunos productos de limpieza como jab√≥n en polvo para ropa, cloro  y otros con olores fuertes. Esto con el fin de prevenir gripe  com√∫n o alergias que amerite salir al m√©dico. . . . quedatencasa usatapabocas lavatelasmanos coronavirus\n",
      "covid covid19 coronavirus secuide cuidedequemvoc√™ama fiqueemcasa\n",
      "La vida nos trae momentos de silencio y aislamiento, aprovechemos para reflexionar sobre las cosas realmente importantes de la vida serendipiacovid  duelo crecimientopersonal coronavirus\n",
      "Self isolation nachos! The homemade queso mixes nicely with the loneliness to create a subtle aroma of doom . . . . . nachos vegetarian vegetariannachos food foodporn isolation coronavirus queso homemade cheese chips quac beans spicy covid_19\n",
      "Toilet paper factory lowpoly lowpolyart  illustration 3dillustration blender3d blender b3d 3D 3Dmodel 3dart digitalart 3drender render rendering artwork cyclesrender 3dartis 3ddesign design  Toiletpaperfactory factory Toiletpaper pandemic pandemia coronavirus armament defense covid19 covid_19\n",
      "yo coronavirus is winning! 11,949 and counting? shit socialdistancing better work. if it doesn‚Äôt work it‚Äôs because people failed. I thought weed be better at this...I guess not. Am I surprised I guess not. Did I hope we could really come together..yea? Am I delusional? Hell yes! fuckit\n",
      "Thank you  smiling face results after one treatment star struck\n",
      "One Man Army 2‚Å† \"Brothers\" . . .‚Å† homeless coronavirus covid19 streetsoftoronto toronto photojournalist lifewithlouis weareallcreators supersweetstreet thecreatorclass createexplore candidphotographer shoot2tell fujifilm XSeries fujinonglobal fujifilm_street thestreetphotographyhub storyofthestreet streetclassics streetfinder streethunters streets_storytelling storyofthestreet streetdreamsmag streetsgrammer lensculturestreets fromstreetswithlove friendsinperson friendsinstreets\n",
      "Um movimento simples que era reflexo primitivo! N√£o subestime a import√¢ncia de fortalecer os p√©s. A√≠ est√° a nossa base! Caso n√£o tenha faixa el√°stica, qualquer pano serve! Esse simples exerc√≠cio √© capaz de: Fortalecer musculaturas extr√≠nsecas e intr√≠nsecas de pernas e p√©s, lubrifica prepara e protege as articula√ß√µes podais. Trabalha lindamente os tr√™s arcos estruturais do p√©. D√° aquele refor√ßo na f√°scea plantar e aprimora a propriocep√ß√£o. institutotorteloti itti pilates massagem aculputura fisioterapia medicinachinesa ficadica saude quarentena ficaemcasa idosos covid19 coronavirus\n",
      "\"Our New Normal\" - Artwork for Turbulent Times face with medical mask face with medical mask face with medical mask coronavirusart coronavirus pandemicart pandemic deafartist mixedmediaartist mixedmedia neworleansartist louisianaartist blingismything\n",
      "sunrise start photography myshots sunset covid_19 staysafe quedateencasa coronaviru createathome creative creativity photooftheday camera artwork artist photography artgallery artdaily dailyart artshub streetphotographyindia oph staysafe indianshutterbugs indiaclicks _coi india_everyday i_hobbygraphy dslr_official staysafestayhome indianphotography coronavirus\n",
      "Si t√∫ amor no vuelve broken heart @greeicy1 @mikebahia . . . . ‚Ä¢ ‚Ä¢ ‚Ä¢ face with medical mask Quarantine ncov2019 fightvirus coronavirus CoronavirusOutbreak toptags covid19 QuarantineLife Quarantined stayinside socialdistancing socialdistance SelfQuarantine QuarantineAndChill stayingin stayingathome staytogether staysafe fighttogether stayhome QuarantineSurvival staypositive coronamemes happyathome care\n",
      "Italian online course from our volunteer Daniel Italy and Gen√ß Giri≈üim Team Italy Turkey Due to the current safety measures, taken by the Ministry of Health, to prevent the spreading of the COVID-19, we will keep going with the Italian and Turkish Lessons on a virtual base, through Skype ƒ∞talya'dan √ºlkemize gelen g√∂n√ºll√ºm√ºz Daniel ile √ßevrimi√ßi ƒ∞talyanca dersimiz! Covid-19 vir√ºs√ºne kar≈üƒ± alƒ±nan √∂nlemler doƒürultusunda Rus√ßa, ƒ∞talyanca ve T√ºrk√ße derslerimizi √ßevrimi√ßi olarak yapmaya devam ediyoruz. @ulusalajans ulusalajans onlinelearning europeancommision erasmusplus stayhome staysafe EU EuropeanUnion Italy Italy Ukraine Ukraine Turkey Turkey Gen√ßGiri≈üim YoungInitiative Italian languagelearning coronavirus\n",
      "Miss Chelsea & Miss Kayra teach us a new game your whole family can play at home! And check back soon for basketball videos from Mr. Chase! Click the link in our bio for the full video with complete rules and to see who won!  throwbackthursday race gym basketball exercise run running boysandgirlsclub beach coronavirus inspiration motivation tbt funny family videooftheday vidoftheday video bestoftheday sandiego  carlsbadvillage carlsbad best sunset thursday socialdistancing\n",
      "I am thoroughly enjoying the time I get to spend at home catching up on my reading! sparkling heart open book sparkling heart reading books book selfisolation isolation socialdistancing covid covid19 coronavirus corona virus peaceful peace\n",
      "The Prisoner. La prigionia √® solo una questione mentale coronavirus photography photo photooftheday photographer  photographylovers photos moda photograph photographers fashionblogger fashion istayathome fashionstyle Dress  Fashion design Detail Trousers designinspiration designer nature naturephotography naturelovers nature_perfection man iorestoacasa freedom istayhome green yoga\n",
      "The Prisoner. La prigionia √® solo una questione mentale coronavirus photography photo photooftheday photographer  photographylovers photos moda photograph photographers fashionblogger fashion lights fashionstyle Dress  Fashion design Detail Trousers designinspiration designer nature naturephotography naturelovers nature_perfection man iorestoacasa freedom istayhome green yoga\n",
      "sanjur montezuma indigenas ng√§bebugl√© 507 coronavirus\n",
      "E infelizmente assim nos despedimos de Madrid. Com a esperan√ßa de dias melhores.... coronavirus quedateencasa fiqueemcasa\n",
      "Did you wash hands properly? Kalamkari version by yours truly :) kalamkari handmudras kalamkarihandmudras howtowashhandsproperly who indianart traditionalart modernkalamkari quarantineartclub quarantineartchallenge covid19 coronavirus coronaart janatacurfew jantacurfew stayathome socialdistancing socialmessage procreate sindhography\n",
      "coronavirus defninde sleepy face i≈ütirak etdik. Seher ola xeyir ola. ƒ∞n≈üaallah bu beladan √∂lkemiz qurtular folded hands light skin tone folded hands light skin tone folded hands light skin tone evdeqal √∂lacƒ±nnan\n",
      "Con esta flor de picada les contamos que este lunes VOLVEMOS! As√≠ que ahora qu√©date en tu casa pero no te pierdas de disfrutar una picada star struck . Si tenes alg√∫n conocido, amigo o familiar que cumplea√±os y este a√±o les toca pasar lejos, tambi√©n cont√°ctanos que nosotros nos encargamos de llevarle una sorpresa como nuestras picadas hasta su domicilio!!. ‚Ä¢A partir del lunes vamos a estar tomando pedidos y continuamos llev√°ndolos a domicilio. ‚Ä¢Seguiremos todas las medidas de higiene correspondiente para como siempre cuidarlos y cuidarnos. . . . . . . . . . . . . . . . picadas picadauruguaya flordepicada montevideo domicilio cumplea√±os familia cuarentena coronavirus\n",
      "Primavera 2020: Expectativas de la gente vs Realidad . . . drawing primavera art spring fanart dibujos covid_19 painting ilustraciones originalart art coronavirus artshare quedateencasa artwork draw artshare originalartwork fancomic stayathome coronavirus\n",
      "Lezione online di sbarra a terra con il corso superiore e alcune delle diplomate red heart rose dancelife iorestoacasa balletto sbarraaterra balletintheageofcorona lezioneonline ballerina ioballodacasa ioballoacasa danzaclassica bestrong coronavirus ladanzanonsiferma nonstopdancing girls danzaclassica dancers ballerine corsosuperiore skype scuoladidanza danzaclassicaaccademica passionedanza lamiadanza salerno\n",
      "„Åû„Éº„Åï„Çì„ÅÆ„Çπ„Éö„Ç∑„É£„É´„É©„É≥„ÉÅ star star star star star star Êñ∞Âûã„Ç≥„É≠„Éä stayhome „É≠„ÉÉ„ÇØ„ÉÄ„Ç¶„É≥ ‰ª§Âíå„Éô„Éì„Éº Êó•Ë®ò ÁµµÊó•Ë®ò Êº´Áîª manga art confinement comics illustration paris ËÇ≤ÂÖêÊó•Ë®ò ËÇ≤ÂÖêÊº´Áîª Â≠êËÇ≤„Å¶Êó•Ë®ò „Ç≥„Éü„ÉÉ„ÇØ„Ç®„ÉÉ„Çª„Ç§ „Éû„Éû„É™ lockdown „Ç≥„É≠„Éä„Ç¶„Ç§„É´„Çπ„ÅåÊó©„ÅèÁµÇÊÅØ„Åó„Åæ„Åô„Çà„ÅÜ„Å´ Ë¶™„Éê„Ç´ÈÉ® Ëµ§„Å°„ÇÉ„Çì„ÅÆ„ÅÑ„ÇãÁîüÊ¥ª coronavirus Êµ∑Â§ñÁîüÊ¥ª Á∑äÊÄ•‰∫ãÊÖãÂÆ£Ë®Ä „Éë„É™ covid_19 ÂüºÁéâ\n",
      "–¢–∞–∫ –º–Ω–æ–≥–æ –≥–æ–≤–æ—Ä—è—Ç –∏ –ø–∏—à—É—Ç –æ–± —ç—Ç–æ–º, –∞ –≤ —á–µ–º –∂–µ —Å—É—Ç—å? –ò –∫–∞–∫–∞—è –≤—ã–≥–æ–¥–∞ –Ω–æ–≤–∏—á–∫—É –∏–ª–∏ –º–∞–º–µ, –∫–æ—Ç–æ—Ä–∞—è —Å–µ–≥–æ–¥–Ω—è –≤ –¥–µ–∫—Ä–µ—Ç–µ? –§—Ä–∞–Ω—à–∏–∑–∞ - —ç—Ç–æ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å –¥–æ–≤–æ–ª—å–Ω–æ –ª—ë–≥–∫–∏–π –∏ –æ—á–µ–Ω—å –ø—Ä–∏–±—ã–ª—å–Ω—ã–π –±–∏–∑–Ω–µ—Å! check mark –°—É—Ç—å –±–∏–∑–Ω–µ—Å–∞: –í—ã –ø—Ä–∏–æ–±—Ä–µ—Ç–∞–µ—Ç–µ —Ñ—Ä–∞–Ω—à–∏–∑—É –∏–ª–∏ –ø–∞–∫–µ—Ç —Ñ—Ä–∞–Ω—à–∏–∑, —Ç–µ–º —Å–∞–º—ã–º –ø–æ–∫—É–ø–∞—è —Å–µ–±–µ —É–∂–µ –≥–æ—Ç–æ–≤—ã–π –±–∏–∑–Ω–µ—Å –ø–ª–∞–Ω, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –Ω–∞—á–∏–Ω–∞—Ç—å –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å, –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–≤–∞—è –µ–≥–æ, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—è —Å–≤–æ—é —Ü–µ–Ω—É! –õ–∏–±–æ –ø–æ —Ñ—Ä–∞–Ω—à–∏–∑–µ –¥–µ–ª–∞—Ç—å –∫–∞–∫–∏–µ –ª–∏–±–æ —Ç–æ–≤–∞—Ä—ã –∏ —Ç–∞–∫ –∂–µ –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–∞ —ç—Ç–æ–º thinking face –§—Ä–∞–Ω—à–∏–∑–∞ ‚Äî —ç—Ç–æ –±–æ–ª—å—à–æ–π –æ–±—ä–µ–º –∏–¥–µ–π (–æ–±—ä–µ–∫—Ç–æ–≤), –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–≤–æ–µ–≥–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–µ–ª–∞/–±–∏–∑–Ω–µ—Å–∞, –ª–∏–±–æ —ç—Ç–æ —É–∂–µ –≥–æ—Ç–æ–≤—ã–π –±–∏–∑–Ω–µ—Å, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∏ –æ–Ω –±—É–¥–µ—Ç –ø—Ä–∏–Ω–æ—Å–∏—Ç—å –¥–æ—Ö–æ–¥! check mark –ö–∞–∫ –∂–µ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ —Ñ—Ä–∞–Ω—à–∏–∑–∞—Ö? –ü–æ–∫—É–ø–∞—è —Ñ—Ä–∞–Ω—à–∏–∑—É, –≤—ã –ø—Ä–∏–æ–±—Ä–µ—Ç–∞–µ—Ç–µ –ª–∏–±–æ —É–∂–µ –≥–æ—Ç–æ–≤—É—é —Å–æ–∑–¥–∞–Ω–Ω—É—é –∏–¥–µ—é (–∫–æ—Ç–æ—Ä—É—é –ø—Ä–æ—Å—Ç–æ –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å), –ª–∏–±–æ –∑–Ω–∞–Ω–∏—è –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—Ç—Ä–µ–±—É—é—Ç—Å—è –≤–∞–º, —á—Ç–æ–±—ã –æ—Ç–∫—Ä—ã—Ç—å —Å–≤–æ–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ –¥–µ–ª–æ –ø–æ —Ç–æ–π –∏–ª–∏ –∏–Ω–æ–π –∏–¥–µ–µ. –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ —ç—Ç–æ —Å—Ç–∞–Ω–µ—Ç –¥–ª—è –≤–∞—Å –æ—á–µ—Ä–µ–¥–Ω—ã–º —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–º —Ö–æ–±–±–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤—ã—à–∏–≤–∫–∞ –º–µ—Ç—Ä–∏–∫ –∏–ª–∏ –ø–ª–µ—Ç–µ–Ω–∏–µ –∏–∑ –±—É–º–∞–≥–∏. –í—Å–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –æ–±—É—á–µ–Ω–∏–µ —É–∂–µ —Å–æ–±—Ä–∞–Ω–æ –¥–ª—è –≤–∞—Å –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ. –í –∫–∞–∂–¥–æ–π —Ñ—Ä–∞–Ω—à–∏–∑–µ –∏–º–µ—é—Ç—Å—è gem stone –î–∏–∑–∞–π–Ω gem stone –°–∞–º–∞ –∏–¥–µ—è —Å–æ –≤—Å–µ–º–∏ –≤—ã—Ç–µ–∫–∞—é—â–∏–º–∏ gem stone –¶–µ–Ω–∞, –∫–∞—á–µ—Å—Ç–≤–æ gem stone –û–±—É—á–µ–Ω–∏–µ, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ gem stone –ü—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ –±–∏–∑–Ω–µ—Å–∞, —Ä–µ–∫–ª–∞–º–∞ check mark –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º: star –§—Ä–∞–Ω—à–∏–∑—ã - —ç—Ç–æ –ø–æ—à–∞–≥–æ–≤—ã–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —Å–≤–æ–µ–≥–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –≤–∞–º –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å –¥–µ–Ω—å–≥–∏ —Å–∏–¥—è –¥–æ–º–∞ –∏ –æ—Å–æ–±–æ –ø—Ä–∏ —ç—Ç–æ–º –Ω–µ –Ω–∞–ø—Ä—è–≥–∞—è—Å—å. star –§—Ä–∞–Ω—à–∏–∑—ã –º–æ–∂–Ω–æ –ø—Ä–æ–¥–∞–≤–∞—Ç—å –¥—Ä—É–≥–∏–º –ª—é–¥—è–º –ø–æ —Å–≤–æ–µ–π —Ü–µ–Ω–µ, –∏ –ø–æ–ª—É—á–∞—Ç—å –ø—Ä–∏ —ç—Ç–æ–º –Ω–µ–ø–ª–æ—Ö—É—é –≤—ã—Ä—É—á–∫—É. star –í–æ —Ñ—Ä–∞–Ω—à–∏–∑–∞—Ö –ø–æ–¥—Ä–æ–±–Ω–æ –æ–ø–∏—Å–∞–Ω—ã \"—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏\" –±–∏–∑–Ω–µ—Å–∞, —Å–ª–µ–¥—É—è –∏–º, –≤—ã —Å–º–æ–∂–µ—Ç–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å, –∫ –ø—Ä–∏–º–µ—Ä—É, –≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω—ã–µ –∞—Ä—Ç—ã –∏ –ø—Ä–æ–¥–∞–≤–∞—Ç—å –∏—Ö. star –ù–∞ –≤—ã–±–æ—Ä –∏–º–µ–µ—Ç—Å—è –±–æ–ª–µ–µ 1000 —Ñ—Ä–∞–Ω—à–∏–∑, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å —á—Ç–æ-—Ç–æ —Å–≤–æ–µ –∏ –∑–∞–Ω—è—Ç—å—Å—è —ç—Ç–∏–º –¥–µ–ª–æ–º, –∞ –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–∞–≤–∞—Ç—å –≤—Å–µ —Ñ—Ä–∞–Ω—à–∏–∑—ã –¥—Ä—É–≥–∏–º –ª—é–¥—è–º. –û—Å—Ç–∞–ª–∏—Å—å –≤–æ–ø—Ä–æ—Å—ã? –ü–∏—à–∏ winking face index pointing up\n"
     ]
    }
   ],
   "source": [
    "for i in range(30): \n",
    "    print(X_ins[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = X[:train_idx], Y_ints[:train_idx]\n",
    "X_val, Y_val = X[train_idx:val_idx], Y_ints[train_idx:val_idx]\n",
    "X_test, Y_test = X[val_idx:], Y_ints[val_idx:]\n",
    "\n",
    "# Tokenize the data\n",
    "X_train_enc = tokenizer(list(X_train), return_tensors='pt', padding=True, truncation=True)\n",
    "X_val_enc = tokenizer(list(X_val), return_tensors='pt', padding=True, truncation=True)\n",
    "X_test_enc = tokenizer(list(X_test), return_tensors='pt', padding=True, truncation=True)\n",
    "X_ins_enc = tokenizer(list(X_ins), return_tensors='pt', padding=True, truncation=True, max_length=308)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define our machine learning model, from our discussion it we can try deep learning models\n",
    "\n",
    "import os\n",
    "from torch.utils.data import (\n",
    "    Dataset, \n",
    "    DataLoader, \n",
    "    RandomSampler, \n",
    "    SequentialSampler\n",
    ")\n",
    "\n",
    "import math \n",
    "from transformers import  (\n",
    "    BertPreTrainedModel, \n",
    "    RobertaConfig, \n",
    "    RobertaTokenizerFast\n",
    ")\n",
    "\n",
    "from transformers.optimization import (\n",
    "    AdamW, \n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from scipy.special import softmax\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    matthews_corrcoef,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    RobertaClassificationHead,\n",
    "    RobertaConfig,\n",
    "    RobertaModel,\n",
    ")\n",
    "\n",
    "from transformers import AutoModel\n",
    "from torch import nn\n",
    "\n",
    "num_labels = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Number of GPUs: ',torch.cuda.device_count())\n",
    "else:\n",
    "    print('No GPU, using CPU.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128 \n",
    "train_batch_size = 8\n",
    "test_batch_size = 8\n",
    "warmup_ratio = 0.06\n",
    "weight_decay=0.0\n",
    "gradient_accumulation_steps = 1\n",
    "num_train_epochs = 5 \n",
    "learning_rate = 1e-05\n",
    "adam_epsilon = 1e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model=\n",
      " RobertaClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
      "  )\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class RobertaClassification(BertPreTrainedModel):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(RobertaClassification, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.roberta = RobertaModel(config)\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        outputs = self.roberta(input_ids,attention_mask=attention_mask)\n",
    "        sequence_output = outputs[0]\n",
    "        \n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        \n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
    "\n",
    "config_class = RobertaConfig\n",
    "model_class = RobertaClassification\n",
    "\n",
    "config = config_class.from_pretrained(MODEL, num_labels=num_labels)\n",
    "model = model_class.from_pretrained(MODEL, config=config)\n",
    "\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, MODEL, num_labels):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.num_labels = num_labels\n",
    "#         self.pretrained_model = AutoModel.from_pretrained(MODEL)\n",
    "# #         self.drop1 = nn.Dropout(0.2)\n",
    "#         self.linear1 = nn.Linear(768, 768)\n",
    "#         self.relu = nn.ReLU()\n",
    "# #         self.drop2 = nn.Dropout(0.2)\n",
    "#         self.linear2 = nn.Linear(768, self.num_labels)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask, labels):\n",
    "#         output = self.pretrained_model(input_ids, attention_mask=attention_mask)\n",
    "#         l1 = self.relu(self.linear1(output.pooler_output))\n",
    "#         out = self.linear2(l1)\n",
    "        \n",
    "#         loss_fct = CrossEntropyLoss()\n",
    "#         loss = loss_fct(out.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "#         return loss, out\n",
    "\n",
    "# model = Model(MODEL, num_labels)\n",
    "print('Model=\\n',model,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-011184b67429>:8: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  self.labels = torch.as_tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "class MyClassificationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data,y):\n",
    "        text = data\n",
    "        labels=y\n",
    "        self.examples = text\n",
    "#         targets = tr.transform(labels)\n",
    "        self.labels = torch.as_tensor(labels, dtype=torch.long)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {key: self.examples[key][index] for key in self.examples}, self.labels[index]\n",
    "\n",
    "\n",
    "train_dataset = MyClassificationDataset(X_train_enc,Y_train)\n",
    "val_dataset = MyClassificationDataset(X_val_enc, Y_val)\n",
    "test_dataset = MyClassificationDataset(X_test_enc, Y_test)\n",
    "ins_dataset = MyClassificationDataset(X_ins_enc, [0.] * len(X_ins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,  7389, 44128,  ...,     1,     1,     1],\n",
      "        [    0,   100,   437,  ...,     1,     1,     1],\n",
      "        [    0,     4,  1437,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 19807,    15,  ...,     1,     1,     1],\n",
      "        [    0,  5975,    51,  ...,     1,     1,     1],\n",
      "        [    0, 13368,   117,  ...,     1,     1,     1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'labels': tensor([1, 3, 1, 0, 0, 2, 1, 0], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 8\n",
    "val_batch_size = 8\n",
    "test_batch_size = 8\n",
    "\n",
    "def get_inputs_dict(batch):\n",
    "    inputs = {key: value.squeeze(1).to(device) for key, value in batch[0].items()}\n",
    "    inputs[\"labels\"] = batch[1].to(device)\n",
    "    return inputs\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset,sampler=train_sampler,batch_size=train_batch_size)\n",
    "\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=val_batch_size)\n",
    "\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=test_batch_size)\n",
    "\n",
    "ins_sampler = SequentialSampler(ins_dataset)\n",
    "ins_dataloader = DataLoader(ins_dataset, sampler=ins_sampler, batch_size=test_batch_size)\n",
    "\n",
    "#Extract a batch as sanity-check\n",
    "batch = get_inputs_dict(next(iter(train_dataloader)))\n",
    "input_ids = batch['input_ids'].to(device)\n",
    "attention_mask = batch['attention_mask'].to(device)\n",
    "labels = batch['labels'].to(device)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_opts(model):\n",
    "    t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\n",
    "    optimizer_grouped_parameters = []\n",
    "    custom_parameter_names = set()\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters.extend(\n",
    "        [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in model.named_parameters()\n",
    "                    if n not in custom_parameter_names and not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in model.named_parameters()\n",
    "                    if n not in custom_parameter_names and any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    warmup_steps = math.ceil(t_total * warmup_ratio)\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "optimizer, scheduler = setup_opts(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train our model using the loaded data\n",
    "model.to(device)\n",
    "\n",
    "model.zero_grad()\n",
    "\n",
    "def log_metrics(y, y_preds):\n",
    "    print(classification_report(y, y_preds, target_names=['Joy', 'Fear', 'Sadness', 'Anger']))\n",
    "    \n",
    "\n",
    "def train_epochs(num_train_epochs):\n",
    "    avg_loss=[]\n",
    "    avg_val_loss=[]\n",
    "    for epoch in range(num_train_epochs):\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss = []\n",
    "    \n",
    "        for batch in train_dataloader:\n",
    "            batch = get_inputs_dict(batch)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            model.zero_grad()\n",
    "            epoch_loss.append(loss.item())\n",
    "        \n",
    "        #evaluate model with test_df at the end of the epoch.\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        n_batches = len(val_dataloader)\n",
    "        preds = np.empty((len(val_dataset), num_labels))\n",
    "        out_label_ids = np.empty((len(val_dataset)))\n",
    "        model.eval()\n",
    "    \n",
    "        for i,test_batch in enumerate(val_dataloader):\n",
    "            with torch.no_grad():\n",
    "                test_batch = get_inputs_dict(test_batch)\n",
    "                input_ids = test_batch['input_ids'].to(device)\n",
    "                attention_mask = test_batch['attention_mask'].to(device)\n",
    "                labels = test_batch['labels'].to(device)\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "                eval_loss += tmp_eval_loss.item()\n",
    "            \n",
    "            nb_eval_steps += 1\n",
    "            start_index = test_batch_size * i\n",
    "            end_index = start_index + test_batch_size if i != (n_batches - 1) else len(test_dataset)\n",
    "            preds[start_index:end_index] = logits.detach().cpu().numpy()\n",
    "            out_label_ids[start_index:end_index] = test_batch[\"labels\"].detach().cpu().numpy()\n",
    "        \n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        model_outputs = preds\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        #result, wrong = compute_metrics(preds, model_outputs, out_label_ids)\n",
    "        epoch_loss=np.mean(epoch_loss)\n",
    "        print('epoch',epoch,'Training avg loss',epoch_loss)\n",
    "        print('epoch',epoch,'Testing  avg loss',eval_loss)\n",
    "        print('---------------------------------------------------\\n')\n",
    "        avg_loss.append(epoch_loss)\n",
    "        avg_val_loss.append(eval_loss)\n",
    "        \n",
    "    report=log_metrics(Y_val, preds)\n",
    "    print(report)\n",
    "    avg_loss=np.mean(avg_loss)\n",
    "    avg_val_loss=np.mean(avg_val_loss)\n",
    "    accuracy=accuracy_score(Y_val, preds)\n",
    "    return avg_loss,avg_val_loss,report,accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():   \n",
    "    model.to(device)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    n_batches = len(test_dataloader)\n",
    "    preds = np.empty((len(test_dataset), num_labels))\n",
    "    out_label_ids = np.empty((len(test_dataset)))\n",
    "    model.eval()\n",
    "    for i,test_batch in enumerate(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            test_batch = get_inputs_dict(test_batch)\n",
    "            input_ids = test_batch['input_ids'].to(device)\n",
    "            attention_mask = test_batch['attention_mask'].to(device)\n",
    "            labels = test_batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "            eval_loss += tmp_eval_loss.item()\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "        start_index = test_batch_size * i\n",
    "        end_index = start_index + test_batch_size if i != (n_batches - 1) else len(test_dataset)\n",
    "        preds[start_index:end_index] = logits.detach().cpu().numpy()\n",
    "        out_label_ids[start_index:end_index] = test_batch[\"labels\"].detach().cpu().numpy()\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    model_outputs = preds\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    print(\"classification report for test set\")\n",
    "    print(log_metrics(Y_test, preds))\n",
    "    accuracy=accuracy_score(Y_test, preds)\n",
    "    return eval_loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train with epochs= 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 Training avg loss 1.1816222612158398\n",
      "epoch 0 Testing  avg loss 0.6051256581322177\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 1 Training avg loss 0.5283586812580203\n",
      "epoch 1 Testing  avg loss 0.4436520438354749\n",
      "---------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Joy       0.85      0.79      0.82       229\n",
      "        Fear       0.86      0.80      0.83       148\n",
      "     Sadness       0.78      0.85      0.81       177\n",
      "       Anger       0.89      0.93      0.91       168\n",
      "\n",
      "    accuracy                           0.84       722\n",
      "   macro avg       0.84      0.84      0.84       722\n",
      "weighted avg       0.84      0.84      0.84       722\n",
      "\n",
      "None\n",
      "classification report for test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Joy       0.83      0.77      0.80       220\n",
      "        Fear       0.84      0.76      0.80       160\n",
      "     Sadness       0.78      0.90      0.83       162\n",
      "       Anger       0.88      0.90      0.89       182\n",
      "\n",
      "    accuracy                           0.83       724\n",
      "   macro avg       0.83      0.83      0.83       724\n",
      "weighted avg       0.83      0.83      0.83       724\n",
      "\n",
      "None\n",
      "train with epochs= 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 Training avg loss 1.205764988471661\n",
      "epoch 0 Testing  avg loss 0.6372908180231577\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 1 Training avg loss 0.5534690967675064\n",
      "epoch 1 Testing  avg loss 0.4580742365547589\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 2 Training avg loss 0.33880221028554486\n",
      "epoch 2 Testing  avg loss 0.4070510159113577\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 3 Training avg loss 0.2398886723354514\n",
      "epoch 3 Testing  avg loss 0.4232915523922542\n",
      "---------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Joy       0.86      0.84      0.85       229\n",
      "        Fear       0.84      0.84      0.84       148\n",
      "     Sadness       0.85      0.82      0.83       177\n",
      "       Anger       0.88      0.93      0.90       168\n",
      "\n",
      "    accuracy                           0.86       722\n",
      "   macro avg       0.86      0.86      0.86       722\n",
      "weighted avg       0.86      0.86      0.86       722\n",
      "\n",
      "None\n",
      "classification report for test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Joy       0.82      0.81      0.82       220\n",
      "        Fear       0.79      0.80      0.80       160\n",
      "     Sadness       0.86      0.86      0.86       162\n",
      "       Anger       0.88      0.88      0.88       182\n",
      "\n",
      "    accuracy                           0.84       724\n",
      "   macro avg       0.84      0.84      0.84       724\n",
      "weighted avg       0.84      0.84      0.84       724\n",
      "\n",
      "None\n",
      "train with epochs= 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 Training avg loss 1.2513474057741272\n",
      "epoch 0 Testing  avg loss 0.7225195212023598\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 1 Training avg loss 0.5447131183644502\n",
      "epoch 1 Testing  avg loss 0.4298951848113275\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 2 Training avg loss 0.32240494855463064\n",
      "epoch 2 Testing  avg loss 0.3977821355501374\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 3 Training avg loss 0.23325595681682723\n",
      "epoch 3 Testing  avg loss 0.39852617472246454\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 4 Training avg loss 0.1765635464807828\n",
      "epoch 4 Testing  avg loss 0.3984152724823126\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 5 Training avg loss 0.1634391503497903\n",
      "epoch 5 Testing  avg loss 0.3984152724823126\n",
      "---------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Joy       0.86      0.86      0.86       229\n",
      "        Fear       0.85      0.86      0.86       148\n",
      "     Sadness       0.85      0.84      0.85       177\n",
      "       Anger       0.91      0.92      0.92       168\n",
      "\n",
      "    accuracy                           0.87       722\n",
      "   macro avg       0.87      0.87      0.87       722\n",
      "weighted avg       0.87      0.87      0.87       722\n",
      "\n",
      "None\n",
      "classification report for test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Joy       0.81      0.81      0.81       220\n",
      "        Fear       0.82      0.79      0.81       160\n",
      "     Sadness       0.84      0.88      0.86       162\n",
      "       Anger       0.91      0.89      0.90       182\n",
      "\n",
      "    accuracy                           0.84       724\n",
      "   macro avg       0.84      0.84      0.84       724\n",
      "weighted avg       0.84      0.84      0.84       724\n",
      "\n",
      "None\n",
      "train with epochs= 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 Training avg loss 1.2514736533604864\n",
      "epoch 0 Testing  avg loss 0.7425822622173435\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 1 Training avg loss 0.6094019524615629\n",
      "epoch 1 Testing  avg loss 0.4634258309481563\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 2 Training avg loss 0.3604557133001375\n",
      "epoch 2 Testing  avg loss 0.4314994557996045\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 3 Training avg loss 0.26455902374208634\n",
      "epoch 3 Testing  avg loss 0.41864777712540313\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 4 Training avg loss 0.2085769503305209\n",
      "epoch 4 Testing  avg loss 0.419260175632579\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 5 Training avg loss 0.187815978806947\n",
      "epoch 5 Testing  avg loss 0.419260175632579\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 6 Training avg loss 0.19299065500387846\n",
      "epoch 6 Testing  avg loss 0.419260175632579\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 7 Training avg loss 0.19604137228506296\n",
      "epoch 7 Testing  avg loss 0.419260175632579\n",
      "---------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Joy       0.85      0.85      0.85       229\n",
      "        Fear       0.84      0.84      0.84       148\n",
      "     Sadness       0.85      0.84      0.84       177\n",
      "       Anger       0.90      0.90      0.90       168\n",
      "\n",
      "    accuracy                           0.86       722\n",
      "   macro avg       0.86      0.86      0.86       722\n",
      "weighted avg       0.86      0.86      0.86       722\n",
      "\n",
      "None\n",
      "classification report for test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Joy       0.81      0.83      0.82       220\n",
      "        Fear       0.82      0.78      0.80       160\n",
      "     Sadness       0.84      0.87      0.86       162\n",
      "       Anger       0.91      0.90      0.90       182\n",
      "\n",
      "    accuracy                           0.85       724\n",
      "   macro avg       0.85      0.84      0.85       724\n",
      "weighted avg       0.85      0.85      0.85       724\n",
      "\n",
      "None\n",
      "train with epochs= 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 Training avg loss 1.3056872443079508\n",
      "epoch 0 Testing  avg loss 0.912159861771615\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 1 Training avg loss 0.6340890712073808\n",
      "epoch 1 Testing  avg loss 0.4488995786305967\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 2 Training avg loss 0.35541239926570894\n",
      "epoch 2 Testing  avg loss 0.4552898897001377\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 3 Training avg loss 0.2598115930615536\n",
      "epoch 3 Testing  avg loss 0.4243820329493546\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 4 Training avg loss 0.20691258078819053\n",
      "epoch 4 Testing  avg loss 0.4268934504732817\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 5 Training avg loss 0.18504840075777246\n",
      "epoch 5 Testing  avg loss 0.4268934504732817\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 6 Training avg loss 0.18980547566502956\n",
      "epoch 6 Testing  avg loss 0.4268934504732817\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 7 Training avg loss 0.19075686567741346\n",
      "epoch 7 Testing  avg loss 0.4268934504732817\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 8 Training avg loss 0.18201502927362478\n",
      "epoch 8 Testing  avg loss 0.4268934504732817\n",
      "---------------------------------------------------\n",
      "\n",
      "epoch 9 Training avg loss 0.17967472616514377\n",
      "epoch 9 Testing  avg loss 0.4268934504732817\n",
      "---------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Joy       0.86      0.85      0.86       229\n",
      "        Fear       0.84      0.83      0.83       148\n",
      "     Sadness       0.82      0.82      0.82       177\n",
      "       Anger       0.89      0.91      0.90       168\n",
      "\n",
      "    accuracy                           0.85       722\n",
      "   macro avg       0.85      0.85      0.85       722\n",
      "weighted avg       0.85      0.85      0.85       722\n",
      "\n",
      "None\n",
      "classification report for test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Joy       0.82      0.82      0.82       220\n",
      "        Fear       0.82      0.78      0.80       160\n",
      "     Sadness       0.83      0.90      0.87       162\n",
      "       Anger       0.90      0.88      0.89       182\n",
      "\n",
      "    accuracy                           0.85       724\n",
      "   macro avg       0.85      0.85      0.85       724\n",
      "weighted avg       0.85      0.85      0.85       724\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "val_acc=[]\n",
    "test_loss=[]\n",
    "test_acc=[]\n",
    "for epoch in range(2,12,2):\n",
    "    print(\"train with epochs=\",epoch)\n",
    "    model = model_class.from_pretrained(MODEL, config=config)\n",
    "#     model = Model(num_labels)\n",
    "    model.to(device)\n",
    "    optimizer, scheduler = setup_opts(model)\n",
    "    \n",
    "    avg_loss,avg_val_loss,report,accuracy=train_epochs(epoch)\n",
    "    \n",
    "    train_loss.append(avg_loss)\n",
    "    val_loss.append(avg_val_loss)\n",
    "    val_acc.append(accuracy)\n",
    "    testloss,testacc=test()\n",
    "    test_loss.append(testloss)\n",
    "    test_acc.append(testacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b07b7ebbfd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=[2,4,6,8,10]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Loss for twitter data\")\n",
    "plt.plot(x,train_loss,marker='o',label='train')\n",
    "plt.plot(x,val_loss,marker='o',label='validation')\n",
    "plt.plot(x,test_loss,marker='o',label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b07bc752310>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Accuracy for twitter data\")\n",
    "plt.plot(x,val_acc,marker='o',label='validation')\n",
    "plt.plot(x,test_acc,marker='o',label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: predict the submission data \n",
    "nb_eval_steps = 0\n",
    "n_batches = len(ins_dataloader)\n",
    "preds = np.empty((len(ins_dataset), num_labels))\n",
    "model.eval()\n",
    "    \n",
    "for i,test_batch in enumerate(ins_dataloader):\n",
    "    with torch.no_grad():\n",
    "        test_batch = get_inputs_dict(test_batch)\n",
    "        input_ids = test_batch['input_ids'].to(device)\n",
    "        attention_mask = test_batch['attention_mask'].to(device)\n",
    "        labels = test_batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        _, logits = outputs[:2]\n",
    "\n",
    "    nb_eval_steps += 1\n",
    "    start_index = test_batch_size * i\n",
    "    end_index = start_index + test_batch_size if i != (n_batches - 1) else len(ins_dataset)\n",
    "    preds[start_index:end_index] = logits.detach().cpu().numpy()\n",
    "\n",
    "model_outputs = preds\n",
    "preds = np.argmax(preds, axis=1)\n",
    "np.savetxt('instagram_predictions.txt', preds) # We might want to do something different here - SN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with Joy: 0.10961711516111323\n",
      "Correlation with Fear: -0.03095183092046343\n",
      "Correlation with Sadness: -0.06202519724378585\n",
      "Correlation with Anger: -0.053837380005938684\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "# from scipy.stats import spearmanr\n",
    "emotions = ['Joy', 'Fear', 'Sadness', 'Anger']\n",
    "\n",
    "preds_one_hot = np.zeros((len(preds), preds.max()+1))\n",
    "preds_one_hot[np.arange(len(preds)),preds] = 1\n",
    "\n",
    "for i in range(num_labels):\n",
    "    corr, _ = pearsonr(preds_one_hot[:,i], east_asian)\n",
    "    print('Correlation with {}: {}'.format(emotions[i], corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Joy \n",
      "Processed:\n",
      "covid covid2020 covidvirus virus coronavairus coronavirus coronav√≠rus coronavir√ºs blackandwhite blackandwhiteportrait blackandwhitephoto blackandwhite_photos lockdown lockdown2020 lockdownlife lockdownitaly italylockdown lockdowndiaries lockdownactivities stayathome staysafe stayhome iorestoacasa myhome covid19 covƒ±d19 coviÃád_19 coviditalia black heart black heart black heart black heart\n",
      "Unprocessed:\n",
      "#covid #covid2020 #covidvirus #virus #coronavairus #coronavirus #coronav√≠rus #coronavir√ºs #blackandwhite #blackandwhiteportrait #blackandwhitephoto #blackandwhite_photos #lockdown #lockdown2020 #lockdownlife #lockdownitaly #italylockdown #lockdowndiaries #lockdownactivities #stayathome #staysafe #stayhome #iorestoacasa #myhome #covid19 #covƒ±d19 #coviÃád_19 #coviditalia #üñ§ #üñ§üñ§üñ§\n",
      "\n",
      "\n",
      "Prediction: Fear \n",
      "Processed:\n",
      "Well this is the final mural of my trip in Australia, a very weird trip, to be honest I couldn‚Äôt connect with my painting, at the beginning it was a popular psicosis which looked unreal, then the airline call me with news that my flights was rebooked for 4 month later, I still had a lot to do, people to meet and paint to make, it was super sad when I had to buy another thicket a week before of planed and run out of the country, the same day they closed the border, I like to think that everything happens for reason, everything is meant to be ... if this is my way to start the painting tour this year I don‚Äôt really know what to expect. When I painted the mural I meant to make something for the woman, for warriors who don‚Äôt want anybody to tell them what to do or say, now it feels empty cos the world is thinking on a different thing. Thank you to my new friend  who really helped and connect with me, what a beautiful city melbourne, what a beautiful country Australia, I hope to be back some day for more projects. Be safe and do what you‚Äôre told, this is not a joke. graff graffiti mural muralart muralgraffiti streetart artecallejero portrait retraro painting pintura realismo realism hiperrealismo hyperrealism portrait retrato onlyspraypaint onlyspray noproyector sinproyector cobreart melbourne australia graffitiaustralia corona coronavirus\n",
      "Unprocessed:\n",
      "Well this is the final mural of my trip in Australia, a very weird trip, to be honest I couldn‚Äôt connect with my painting, at the beginning it was a popular psicosis which looked unreal, then the airline call me with news that my flights was rebooked for 4 month later, I still had a lot to do, people to meet and paint to make, it was super sad when I had to buy another thicket a week before of planed and run out of the country, the same day they closed the border, I like to think that everything happens for reason, everything is meant to be ... if this is my way to start the painting tour this year I don‚Äôt really know what to expect. When I painted the mural I meant to make something for the woman, for warriors who don‚Äôt want anybody to tell them what to do or say, now it feels empty cos the world is thinking on a different thing. Thank you to my new friend @r_o_n_e who really helped and connect with me, what a beautiful city melbourne, what a beautiful country Australia, I hope to be back some day for more projects. Be safe and do what you‚Äôre told, this is not a joke. \r",
      "\r",
      "\r",
      "\r\n",
      "#graff#graffiti#mural#muralart#muralgraffiti#streetart#artecallejero#portrait#retraro#painting#pintura#realismo#realism#hiperrealismo#hyperrealism#portrait#retrato#onlyspraypaint#onlyspray#noproyector#sinproyector#cobreart#melbourne#australia#graffitiaustralia#corona#coronavirus\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "Chegamos !!! V√£o seguindo o movimento... Tem muita coisa que estamos preparando pra voc√™s!!!\n",
      "Unprocessed:\n",
      "Chegamos !!! V√£o seguindo o movimento... Tem muita coisa que estamos preparando pra voc√™s!!!\n",
      "\n",
      "\n",
      "Prediction: Anger \n",
      "Processed:\n",
      "smiling cat with heart eyes smiling cat with heart eyes smiling cat with heart eyes smiling cat with heart eyes smiling cat with heart eyes\n",
      "Unprocessed:\n",
      "üòªüòªüòªüòªüòª\n",
      "\n",
      "\n",
      "Prediction: Sadness \n",
      "Processed:\n",
      "EN MI DOMICILIO house with garden quedateencasa mobile phone with arrow 0414-464.18.89 . USA TAPA BOCAS face with medical mask . Tapa bocas seguros y c√≥modos Un obsequio de   bikini Graciasss . A√∫n en nuestro hogares deber√≠amos usa tapa bocas, al usar algunos productos de limpieza como jab√≥n en polvo para ropa, cloro  y otros con olores fuertes. Esto con el fin de prevenir gripe  com√∫n o alergias que amerite salir al m√©dico. . . . quedatencasa usatapabocas lavatelasmanos coronavirus\n",
      "Unprocessed:\n",
      "EN MI DOMICILIO üè°\r",
      "\r",
      "\r",
      "\r\n",
      "#quedateencasa\r",
      "\r",
      "\r",
      "\r\n",
      "üì≤ 0414-464.18.89\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      "USA TAPA BOCASüò∑\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      "Tapa bocas seguros y c√≥modos\r",
      "\r",
      "\r",
      "\r\n",
      "Un obsequio de  @strongirlslingerie üëô\r",
      "\r",
      "\r",
      "\r\n",
      "Graciasss\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      "A√∫n en nuestro hogares deber√≠amos usa tapa bocas, \r",
      "\r",
      "\r",
      "\r\n",
      "al usar algunos productos de limpieza como jab√≥n en polvo para ropa, cloro  y otros con olores fuertes. Esto con el fin de prevenir gripe  com√∫n o alergias que amerite salir al m√©dico.\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      "#quedatencasa #usatapabocas #lavatelasmanos #coronavirus\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "covid covid19 coronavirus secuide cuidedequemvoc√™ama fiqueemcasa\n",
      "Unprocessed:\n",
      "#covid #covid19 #coronavirus #secuide #cuidedequemvoc√™ama #fiqueemcasa\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "La vida nos trae momentos de silencio y aislamiento, aprovechemos para reflexionar sobre las cosas realmente importantes de la vida serendipiacovid  duelo crecimientopersonal coronavirus\n",
      "Unprocessed:\n",
      "La vida nos trae momentos de silencio y aislamiento, aprovechemos para reflexionar sobre las cosas realmente importantes de la vida #serendipiacovid  #duelo #crecimientopersonal #coronavirus\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "Self isolation nachos! The homemade queso mixes nicely with the loneliness to create a subtle aroma of doom . . . . . nachos vegetarian vegetariannachos food foodporn isolation coronavirus queso homemade cheese chips quac beans spicy covid_19\n",
      "Unprocessed:\n",
      "Self isolation nachos! The homemade queso mixes nicely with the loneliness to create a subtle aroma of doom\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      "#nachos #vegetarian #vegetariannachos #food #foodporn #isolation #coronavirus #queso #homemade #cheese #chips #quac #beans #spicy #covid_19\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "Toilet paper factory lowpoly lowpolyart  illustration 3dillustration blender3d blender b3d 3D 3Dmodel 3dart digitalart 3drender render rendering artwork cyclesrender 3dartis 3ddesign design  Toiletpaperfactory factory Toiletpaper pandemic pandemia coronavirus armament defense covid19 covid_19\n",
      "Unprocessed:\n",
      "Toilet paper factory\r",
      "\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r",
      "\r\n",
      "#lowpoly #lowpolyart  #illustration #3dillustration\r",
      "\r",
      "\r",
      "\r\n",
      "#blender3d #blender #b3d #3D #3Dmodel #3dart #digitalart #3drender #render #rendering #artwork #cyclesrender #3dartis #3ddesign #design  #Toiletpaperfactory #factory #Toiletpaper #pandemic #pandemia #coronavirus #armament #defense #covid19 #covid_19\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "yo coronavirus is winning! 11,949 and counting? shit socialdistancing better work. if it doesn‚Äôt work it‚Äôs because people failed. I thought weed be better at this...I guess not. Am I surprised I guess not. Did I hope we could really come together..yea? Am I delusional? Hell yes! fuckit\n",
      "Unprocessed:\n",
      "#yo #coronavirus is winning! 11,949 and counting? #shit #socialdistancing better work. #if it doesn‚Äôt work it‚Äôs because people failed. I thought #weed be better at this...I guess not. Am I #surprised I guess not. Did I hope we could really come together..yea? Am I delusional? Hell yes! #fuckit\n",
      "\n",
      "\n",
      "Prediction: Anger \n",
      "Processed:\n",
      "Thank you  smiling face results after one treatment star struck\n",
      "Unprocessed:\n",
      "Thank you @bbn_donibziee ‚ò∫Ô∏è results after one treatment ü§©\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "One Man Army 2‚Å† \"Brothers\" . . .‚Å† homeless coronavirus covid19 streetsoftoronto toronto photojournalist lifewithlouis weareallcreators supersweetstreet thecreatorclass createexplore candidphotographer shoot2tell fujifilm XSeries fujinonglobal fujifilm_street thestreetphotographyhub storyofthestreet streetclassics streetfinder streethunters streets_storytelling storyofthestreet streetdreamsmag streetsgrammer lensculturestreets fromstreetswithlove friendsinperson friendsinstreets\n",
      "Unprocessed:\n",
      "One Man Army 2‚Å† \"Brothers\"\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      ". .‚Å†\r",
      "\r",
      "\r",
      "\r\n",
      "#homeless #coronavirus #covid19 #streetsoftoronto #toronto #photojournalist #lifewithlouis #weareallcreators #supersweetstreet #thecreatorclass #createexplore #candidphotographer #shoot2tell #fujifilm #XSeries #fujinonglobal #fujifilm_street #thestreetphotographyhub #storyofthestreet #streetclassics #streetfinder #streethunters #streets_storytelling #storyofthestreet #streetdreamsmag #streetsgrammer #lensculturestreets #fromstreetswithlove #friendsinperson #friendsinstreets\n",
      "\n",
      "\n",
      "Prediction: Sadness \n",
      "Processed:\n",
      "Um movimento simples que era reflexo primitivo! N√£o subestime a import√¢ncia de fortalecer os p√©s. A√≠ est√° a nossa base! Caso n√£o tenha faixa el√°stica, qualquer pano serve! Esse simples exerc√≠cio √© capaz de: Fortalecer musculaturas extr√≠nsecas e intr√≠nsecas de pernas e p√©s, lubrifica prepara e protege as articula√ß√µes podais. Trabalha lindamente os tr√™s arcos estruturais do p√©. D√° aquele refor√ßo na f√°scea plantar e aprimora a propriocep√ß√£o. institutotorteloti itti pilates massagem aculputura fisioterapia medicinachinesa ficadica saude quarentena ficaemcasa idosos covid19 coronavirus\n",
      "Unprocessed:\n",
      "Um movimento simples que era reflexo primitivo! N√£o subestime a import√¢ncia de fortalecer os p√©s. A√≠ est√° a nossa base!\r",
      "\r",
      "\r",
      "\r\n",
      "Caso n√£o tenha faixa el√°stica, qualquer pano serve!\r",
      "\r",
      "\r",
      "\r\n",
      "Esse simples exerc√≠cio √© capaz de: Fortalecer musculaturas extr√≠nsecas e intr√≠nsecas de pernas e p√©s, lubrifica prepara e protege as articula√ß√µes podais. Trabalha lindamente os tr√™s arcos estruturais do p√©. D√° aquele refor√ßo na f√°scea plantar e aprimora a propriocep√ß√£o.\r",
      "\r",
      "\r",
      "\r\n",
      "#institutotorteloti\r",
      "\r",
      "\r",
      "\r\n",
      "#itti\r",
      "\r",
      "\r",
      "\r\n",
      "#pilates\r",
      "\r",
      "\r",
      "\r\n",
      "#massagem\r",
      "\r",
      "\r",
      "\r\n",
      "#aculputura\r",
      "\r",
      "\r",
      "\r\n",
      "#fisioterapia\r",
      "\r",
      "\r",
      "\r\n",
      "#medicinachinesa\r",
      "\r",
      "\r",
      "\r\n",
      "#ficadica\r",
      "\r",
      "\r",
      "\r\n",
      "#saude\r",
      "\r",
      "\r",
      "\r\n",
      "#quarentena\r",
      "\r",
      "\r",
      "\r\n",
      "#ficaemcasa\r",
      "\r",
      "\r",
      "\r\n",
      "#idosos\r",
      "\r",
      "\r",
      "\r\n",
      "#covid19\r",
      "\r",
      "\r",
      "\r\n",
      "#coronavirus\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "\"Our New Normal\" - Artwork for Turbulent Times face with medical mask face with medical mask face with medical mask coronavirusart coronavirus pandemicart pandemic deafartist mixedmediaartist mixedmedia neworleansartist louisianaartist blingismything\n",
      "Unprocessed:\n",
      "\"Our New Normal\" - Artwork for Turbulent Times üò∑üò∑üò∑ #coronavirusart #coronavirus #pandemicart #pandemic #deafartist #mixedmediaartist #mixedmedia #neworleansartist #louisianaartist #blingismything\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "sunrise start photography myshots sunset covid_19 staysafe quedateencasa coronaviru createathome creative creativity photooftheday camera artwork artist photography artgallery artdaily dailyart artshub streetphotographyindia oph staysafe indianshutterbugs indiaclicks _coi india_everyday i_hobbygraphy dslr_official staysafestayhome indianphotography coronavirus\n",
      "Unprocessed:\n",
      "#sunrise #start #photography #myshots#sunset\r",
      "\r",
      "\r",
      "\r\n",
      "#covid_19 #staysafe #quedateencasa #coronaviru #createathome #creative #creativity #photoofthedayüì∑ #artwork #artist #photography #artgallery #artdaily #dailyart #artshub #streetphotographyindia #oph #staysafe #indianshutterbugs #indiaclicks #_coi #india_everyday #i_hobbygraphy #dslr_official #staysafestayhome #indianphotography #coronavirus\n",
      "\n",
      "\n",
      "Prediction: Fear \n",
      "Processed:\n",
      "Si t√∫ amor no vuelve broken heart @greeicy1 @mikebahia . . . . ‚Ä¢ ‚Ä¢ ‚Ä¢ face with medical mask Quarantine ncov2019 fightvirus coronavirus CoronavirusOutbreak toptags covid19 QuarantineLife Quarantined stayinside socialdistancing socialdistance SelfQuarantine QuarantineAndChill stayingin stayingathome staytogether staysafe fighttogether stayhome QuarantineSurvival staypositive coronamemes happyathome care\n",
      "Unprocessed:\n",
      "Si t√∫ amor no vuelve üíî\r",
      "\r",
      "\r",
      "\r\n",
      "@greeicy1 \r",
      "\r",
      "\r",
      "\r\n",
      "@mikebahia .\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      ".\r",
      "\r",
      "\r",
      "\r\n",
      "‚Ä¢\r",
      "\r",
      "\r",
      "\r\n",
      "‚Ä¢\r",
      "\r",
      "\r",
      "\r\n",
      "‚Ä¢\r",
      "\r",
      "\r",
      "\r\n",
      "üò∑ #Quarantine #ncov2019 #fightvirus #coronavirus #CoronavirusOutbreak #toptags #covid19 #QuarantineLife #Quarantined #stayinside #socialdistancing #socialdistance #SelfQuarantine #QuarantineAndChill #stayingin #stayingathome #staytogether #staysafe #fighttogether #stayhome #QuarantineSurvival #staypositive #coronamemes #happyathome #care\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "Italian online course from our volunteer Daniel Italy and Gen√ß Giri≈üim Team Italy Turkey Due to the current safety measures, taken by the Ministry of Health, to prevent the spreading of the COVID-19, we will keep going with the Italian and Turkish Lessons on a virtual base, through Skype ƒ∞talya'dan √ºlkemize gelen g√∂n√ºll√ºm√ºz Daniel ile √ßevrimi√ßi ƒ∞talyanca dersimiz! Covid-19 vir√ºs√ºne kar≈üƒ± alƒ±nan √∂nlemler doƒürultusunda Rus√ßa, ƒ∞talyanca ve T√ºrk√ße derslerimizi √ßevrimi√ßi olarak yapmaya devam ediyoruz. @ulusalajans ulusalajans onlinelearning europeancommision erasmusplus stayhome staysafe EU EuropeanUnion Italy Italy Ukraine Ukraine Turkey Turkey Gen√ßGiri≈üim YoungInitiative Italian languagelearning coronavirus\n",
      "Unprocessed:\n",
      "Italian online course from our volunteer Daniel üáÆüáπ and Gen√ß Giri≈üim Team üáÆüáπüáπüá∑\r",
      "\r",
      "\r",
      "\r\n",
      "Due to the current safety measures, taken by the Ministry of Health, to prevent the spreading of the COVID-19, we will keep going with the Italian and Turkish Lessons on a virtual base, through Skype\r",
      "\r",
      "\r",
      "\r\n",
      "ƒ∞talya'dan √ºlkemize gelen g√∂n√ºll√ºm√ºz Daniel ile √ßevrimi√ßi ƒ∞talyanca dersimiz! Covid-19 vir√ºs√ºne kar≈üƒ± alƒ±nan √∂nlemler doƒürultusunda Rus√ßa, ƒ∞talyanca ve T√ºrk√ße derslerimizi √ßevrimi√ßi olarak yapmaya devam ediyoruz.\r",
      "\r",
      "\r",
      "\r\n",
      "@ulusalajans \r",
      "\r",
      "\r",
      "\r\n",
      "#ulusalajans #onlinelearning #europeancommision #erasmusplus #stayhome #staysafe #EU #EuropeanUnion #ItalyüáÆüáπ #Ukraineüá∫üá¶ #Turkeyüáπüá∑ #Gen√ßGiri≈üim #YoungInitiative #Italian #languagelearning #coronavirus\n",
      "\n",
      "\n",
      "Prediction: Anger \n",
      "Processed:\n",
      "Miss Chelsea & Miss Kayra teach us a new game your whole family can play at home! And check back soon for basketball videos from Mr. Chase! Click the link in our bio for the full video with complete rules and to see who won!  throwbackthursday race gym basketball exercise run running boysandgirlsclub beach coronavirus inspiration motivation tbt funny family videooftheday vidoftheday video bestoftheday sandiego  carlsbadvillage carlsbad best sunset thursday socialdistancing\n",
      "Unprocessed:\n",
      "Miss Chelsea & Miss Kayra teach us a new game your whole family can play at home!\r",
      "\r",
      "\r",
      "\r\n",
      "And check back soon for basketball videos from Mr. Chase!\r",
      "\r",
      "\r",
      "\r\n",
      "Click the link in our bio for the full video with complete rules and to see who won! @theellenshow\r",
      "\r",
      "\r",
      "\r\n",
      "#tictactoe #throwbackthursday #race #gym #basketball #exercise #run #running #boysandgirlsclub #beach #coronavirus #inspiration #motivation #tbt #funny #family #videooftheday #vidoftheday #video #bestoftheday #sandiego  #carlsbadvillage #carlsbad #best #sunset #thursday #socialdistancing\n",
      "\n",
      "\n",
      "Prediction: Anger \n",
      "Processed:\n",
      "I am thoroughly enjoying the time I get to spend at home catching up on my reading! sparkling heart open book sparkling heart reading books book selfisolation isolation socialdistancing covid covid19 coronavirus corona virus peaceful peace\n",
      "Unprocessed:\n",
      "I am thoroughly enjoying the time I get to spend at home catching up on my reading! üíñüìñüíñ #reading #books #book #selfisolation #isolation #socialdistancing #covid #covid19 #coronavirus #corona #virus #peaceful #peace\n",
      "\n",
      "\n",
      "Prediction: Joy \n",
      "Processed:\n",
      "The Prisoner. La prigionia √® solo una questione mentale coronavirus photography photo photooftheday photographer  photographylovers photos moda photograph photographers fashionblogger fashion istayathome fashionstyle Dress  Fashion design Detail Trousers designinspiration designer nature naturephotography naturelovers nature_perfection man iorestoacasa freedom istayhome green yoga\n",
      "Unprocessed:\n",
      "The Prisoner. La prigionia √® solo una questione mentale #coronavirus #photography #photo #photooftheday #photographer  #photographylovers #photos #moda #photograph #photographers #fashionblogger #fashion #istayathome #fashionstyle #Dress  #Fashion #design #Detail #Trousers #designinspiration #designer #nature #naturephotography #naturelovers #nature_perfection #man #iorestoacasa #freedom #istayhome #green #yoga\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print('Prediction: {} \\nProcessed:\\n{}\\nUnprocessed:\\n{}\\n\\n'.format(emotions[preds[i]], X_ins[i],np.array(ins_df['Contents'])[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
